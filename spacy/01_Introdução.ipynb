{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284c4dbb-6158-4e0f-9786-478d9a169ed8",
   "metadata": {},
   "source": [
    "# Introdução a biblioteca spaCy\n",
    "\n",
    "\n",
    "# O objeto nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c3c9f6-eb87-483b-bde3-12a1244f06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar a biblioteca spaCY\n",
    "import spacy\n",
    "\n",
    "# Criar um objeto nlp vazio da lingua portuguesa\n",
    "nlp = spacy.blank (\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f38ea-34be-4900-8d13-94f5a582eb82",
   "metadata": {},
   "source": [
    "\n",
    "- contém o fluxo de processamento\n",
    "- inclui regras específicas da linguagem, como toquenização etc.\n",
    "\n",
    "Notes: No cerne da spaCy está o objeto nlp, que contém o fluxo de processamento. Por convenção, normalmente chamamos essa variável de \"nlp\".\n",
    "\n",
    "Como exemplo, para criar o objeto `nlp` em inglês, importamos a biblioteca `spacy`  e usamos `spacy.blank` para criar um\n",
    "fluxo de processamento (pipeline) vazio. Podemos utilizar o objeto nlp como se chamássemos uma função para analisar  textos.\n",
    "\n",
    "O objeto contém os diferentes componentes do fluxo de processamento do texto.\n",
    "\n",
    "Ele também contém regras específicas de cada idioma para a toquenização do texto em palavras e pontuação. A spaCy oferece suporte para diversos idiomas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059899bf-8356-44de-a067-5b091f5ccbd6",
   "metadata": {},
   "source": [
    "# O objeto Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b965d2c2-1a31-4b71-afcd-cf1d9cb6cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá\n",
      "mundo\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# Criado após processar um texto com o objeto nlp\n",
    "doc = nlp(\"Olá mundo!\")\n",
    "\n",
    "# Iterar nos tokens do Doc\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910c87b6-aaa7-4411-82f5-1bc44beed08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mundo"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed817b-ddfc-4ed5-ad53-2baf5ed80734",
   "metadata": {},
   "source": [
    "\n",
    "Notes: Quando você processa um texto com o objeto `nlp`, a spaCy cria um objeto `Doc`- abreviação de \"documento\". Através do Doc é possível acessar informações do texto de uma maneira estruturada, sendo que nenhuma informação é perdida.\n",
    "\n",
    "O Doc se comporta de maneira semelhante a uma sequência do Python, permitindo a iteração nos tokens e o acesso a um token através do seu índice. Mas falaremos disso mais tarde!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f7c69-1051-43d9-8fe5-3c7aede859cb",
   "metadata": {},
   "source": [
    "# O objeto Token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75190b-0612-40d2-9078-b510e2d0fa25",
   "metadata": {},
   "source": [
    "<img src=\"doc.png\" alt=\"Ilustração de um objeto Doc contendo três tokens\" width=\"50%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653aceec-dc91-4776-b550-6b1ec296b480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mundo\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Olá Mundo!\")\n",
    "\n",
    "# Indexar o Doc para obter um Token\n",
    "token = doc[1]\n",
    "\n",
    "# Obter o texto do token através do atributo .text\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89044b82-6982-4e18-9ec8-3ba2532ca6f1",
   "metadata": {},
   "source": [
    "Notes: O objeto `Token` representa uma parte do texto: uma palavra ou um caracter de pontuação.\n",
    "\n",
    "Para acessar um token em uma posição específica, você pode indexar o objeto Doc.\n",
    "\n",
    "Os objetos `Token` também contêm vários atributos que permitem acessar mais informações sobre os tokens. Por exemplo: o atributo `.text` retorna o texto _verbatim_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab454d9-9085-40e8-9c9e-5b54adfdc478",
   "metadata": {},
   "source": [
    "# O objeto Partição (Span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ef278-75f2-4ed9-a141-ecbe794038c7",
   "metadata": {},
   "source": [
    "<img src=\"doc_span.png\" width=\"50%\" alt=\"Ilustração de um objeto Doc com três tokens e dois deles agrupados em uma Partição.\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cdfdefa-9596-4aa7-8dff-2912c7b51c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá Mundo!\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Olá Mundo!\")\n",
    "\n",
    "# Um pedaço do Doc é um objeto Partição (Span) \n",
    "span = doc[:3]\n",
    "\n",
    "# Obter o texto da partição com o atributo .text\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ef3be-7d7e-45fb-b84a-99c0f5834f13",
   "metadata": {},
   "source": [
    "\n",
    "Notes: Um objeto partição `Span` é uma partição do documento consistindo de um ou mais tokens. É apenas um apontamento para o `Doc` e não contém dados em si mesmo.\n",
    "\n",
    "Para criar uma partição, você pode usar a notação de partição do Python. Por exemplo, `1:3` criará uma partição do token na posição 1 até o token na partição 3, mas não incluindo este último.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db915d7d-05ff-4c72-b261-9d084f433e9e",
   "metadata": {},
   "source": [
    "# Atributos léxicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be386f0f-79ab-4b97-b5ba-b8eb23c50841",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Isto custa R$5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0213b0-7fdc-4b01-a527-786415601050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:    [0, 1, 2, 3, 4]\n",
      "Text:     ['Isto', 'custa', 'R$', '5', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Index:   \", [token.i for token in doc])\n",
    "print(\"Text:    \", [token.text for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70ef9ca3-337b-4adf-9a6f-18eb2d353f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1054dd4a-0f61-4329-a164-20e26389cd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6058f014-92fc-4cf9-b20f-cc3e03863e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4a863d5-7c00-46ad-aa35-3b6db5c2b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfabéticos: [True, True, False, False, False]\n",
      "Pontuação : [False, False, False, False, True]\n",
      "Numeração: [False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "print(\"Alfabéticos:\", [token.is_alpha for token in doc])\n",
    "print(\"Pontuação :\", [token.is_punct for token in doc])\n",
    "print(\"Numeração:\", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e20cd-7a80-49c5-9447-0e554c50c890",
   "metadata": {},
   "source": [
    "Notes: Aqui você pode observar alguns dos atributos dos tokens disponíveis :\n",
    "\n",
    "`i` é o índice do token no documento principal.\n",
    "\n",
    "`text` retorna o texto do documento.\n",
    "\n",
    "`is_alpha`, `is_punct` e `like_num` retornam valores boleanos (verdadeiro ou falso) indicando respectivamente se o token tem caracteres alfabéticos, se é uma pontuação ou se _assemelha-se_ a um número, por exemplo, o token \"10\" – um, zero – ou a palavra \"dez\" – D,E,Z.\n",
    "\n",
    "Esses atributos são também chamados de atributos léxicos: referem-se ao token em si e não dependem de nenhum contexto no qual o token está inserido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb4d101c-5021-4090-bfc9-747857684a0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[E001] No component 'tagger' found in pipeline. Available names: []\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pos_labels \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtagger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlabels\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLista de POS disponíveis no modelo:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m pos_labels:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/language.py:650\u001b[0m, in \u001b[0;36mLanguage.get_pipe\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pipe_name \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m component\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE001\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names))\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[E001] No component 'tagger' found in pipeline. Available names: []\""
     ]
    }
   ],
   "source": [
    "pos_labels = nlp.get_pipe(\"tagger\").labels\n",
    "\n",
    "print(\"Lista de POS disponíveis no modelo:\")\n",
    "for pos in pos_labels:\n",
    "    print(f\"{pos}: {spacy.explain(pos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47852dbc-9100-4ab8-b343-7787fb078b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9cad4-b376-4cd1-96c5-e8322086ea14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
